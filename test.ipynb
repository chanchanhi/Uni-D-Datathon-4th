{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "# 데이터셋 경로\n",
    "noisy_data_path = 'C:/Users/p8528/Desktop/test_search/Uni-D-Datathon-4th/test'\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, noisy_image_paths, transform=None):\n",
    "        # 주어진 디렉토리 내의 이미지 파일 경로 리스트를 생성합니다.\n",
    "        self.noisy_image_paths = [\n",
    "            os.path.join(noisy_image_paths, x) for x in os.listdir(noisy_image_paths) \n",
    "            if x.endswith(('jpg', 'png', 'jpeg'))\n",
    "        ]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy_image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 이미지 경로 가져오기\n",
    "        noisy_image_path = self.noisy_image_paths[index]\n",
    "        \n",
    "        # 이미지 불러오기\n",
    "        noisy_image = Image.open(noisy_image_path).convert(\"RGB\")\n",
    "        \n",
    "        # 전처리가 이미 되어 있으므로 추가 변환은 필요하지 않지만, transform이 있을 경우 적용합니다.\n",
    "        if self.transform:\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "        \n",
    "        return noisy_image, noisy_image_path  # 정답 레이블 없이 이미지와 경로만 반환\n",
    "\n",
    "# transform 예시 (필요 시에만 사용)\n",
    "transform = ToTensor()\n",
    "\n",
    "# 데이터셋 사용 예시\n",
    "test_dataset = CustomDataset(noisy_image_paths=noisy_data_path, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\p8528\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\p8528\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\p8528\\AppData\\Local\\Temp\\ipykernel_8912\\3112979124.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('resnet18_final.pth', map_location=device))\n",
      "Predicting: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Device 설정 (CUDA가 가능한 경우 CUDA 사용)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 설정 및 가중치 로드\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 20)  # 클래스 수에 맞게 출력 설정\n",
    "model = model.to(device)  # 모델을 CUDA로 이동\n",
    "model.load_state_dict(torch.load('resnet18_final.pth'))\n",
    "model.eval()  # 평가 모드로 설정\n",
    "\n",
    "predicted_results = []  # 예측 결과 저장할 리스트\n",
    "\n",
    "# 예측 수행\n",
    "with torch.no_grad():\n",
    "    for images, image_paths in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        images = images.to(device)  # 이미지를 CUDA로 이동\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # 이미지 경로와 예측된 라벨 저장\n",
    "        for i in range(len(predicted)):\n",
    "            predicted_results.append([\n",
    "                image_paths[i],\n",
    "                predicted[i].item()\n",
    "            ])\n",
    "\n",
    "# 예측 결과 확인\n",
    "for result in predicted_results[:5]:  # 상위 5개 결과 미리보기\n",
    "    print(f\"Image path: {result[0]}, Predicted label: {result[1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
